---
---


<br>
<br>



<div align="center">
	<h1>About</h1>
</div>


<br>
<br>

<br>
<br>
<br>

### Motivations

<br>
<br>
<br>

<div align="center">
	<img src="/assets/logos/index/top_down_robot_arm.png" style="width:200px;"><img src="/assets/logos/index/imitation_learning_robot_arm.png" style="width:200px;">
</div>


<br>

<p align="justify"> 
<font style="font-size:1.3rem;font-family:'Georgia',serif;"><b>Learning to grasp</b> in robotics is still a <b>partially solved problem</b>. The inherent reward sparsity of this task make it hardly tractable for state-of-the-art reinforcement learning methods. Most of the latest works avoid the exploration problem by constraining the operational space through the use of reward shaping, imitation learning from a few demonstrations, parallel gripper, and top-down movements.</font>
</p> 

<br>
<br>
<br>
<br>

<div align="center">
	<img src="https://www.zupimages.net/up/23/40/qums.png" style="width:400px;">
</div>

<br>

<p align="justify"> 
<font style="font-size:1.3rem;font-family:'Georgia',serif;">However, the AI breakthroughs of the last decade show that <b>generalization requires large and high-quality datasets</b>.</font>
</p>

<br>
<br>
<br>
<br>

<p align="justify"> 
<font style="font-size:1.3rem;font-family:'Georgia',serif;"><b>Quality-Diversity (QD)</b> methods are optimization algorithms that aims to find a set of diverse and high-performing solution to a given problem. Recent works have demonstrate how QD methods <b>can be used to generate datasets</b> – including adversarial objects to grasp (Morrison et al., 2020) and demonstrations to learn locomotion policies in a supervised way (Macé et al. 2023).</font>
</p>

<br>
<br>
<br>
<br>

<div align="center">
	<img src="/assets/logos/index/qd_robot_arm_arrows_crop_rz.png" style="width:200px;">
</div>

<p align="justify"> 
<font style="font-size:1.3rem;font-family:'Georgia',serif;">The <b>QD-Grasp</b> project aims to <b>leverage the QD capabilities for generating datasets</b> in order to address the hard exploration challenge of <b>learning to grasp in robotics</b>.</font>
</p>




<br>
<br>
<br>
<br>
<br>
<br>

<u>References:</u>

<i>Morrison, D., Corke, P., & Leitner, J. (2020). Egad! an evolved grasping analysis dataset for diversity and reproducibility in robotic manipulation. IEEE Robotics and Automation Letters, 5(3), 4368-4375.</i>

<br>

<i>Macé, V., Boige, R., Chalumeau, F., Pierrot, T., Richard, G., & Perrin-Gilbert, N. (2023). The Quality-Diversity Transformer: Generating Behavior-Conditioned Trajectories with Decision Transformers. arXiv preprint arXiv:2303.16207.</i>


<br>
<br>
<br>
<br>
<br>
<br>

### Authors

<br>

<i>By alphabetical order</i>

Faïz Ben Amar, François Hélénon, Hippolythe Watrelot, Johann Huber, Miranda Coninx, Stéphane Doncieux


<br>
<br>
<br>
<br>
<br>
<br>


### Sponsors

<br>
<br>

<p style="text-align:center;">
	<img src="https://www.zupimages.net/up/23/40/tnes.png" width="1000">
</p>

<p style="text-align:center;">
	<img src="/assets/logos/index/sponsors_2.png" width="1000">
</p> 

<br>
<br>

<p style="text-align:center;">
	<a href="https://pillar-robots.eu/">Pillar Robots</a> &bull; <a href="https://www.eurobin-project.eu/">euROBIN</a> &bull; <a href="https://www.isir.upmc.fr/projects/learning-human-like-interactivegrasping-based-on-visual-and-haptic-feedback/?lang=en/">Learn2Grasp </a>
</p>

<br>
<br>





